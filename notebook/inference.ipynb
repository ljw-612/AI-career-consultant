{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/jingwei/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_KEY\"] = \"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\"\n",
    "\n",
    "login(\n",
    "    token=os.environ.get('HF_KEY'),\n",
    "    add_to_git_credential=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Pot-l/bert-ner-skills\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'B-Skill': 1, 'I-Skill': 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worddf = pd.read_csv('../data/words_df.csv')\n",
    "label2id = {k: v for v, k in enumerate(worddf.Tag.unique())}\n",
    "id2label = {v: k for v, k in enumerate(worddf.Tag.unique())}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def read_pdf_as_string(file_path):\n",
    "    # Open the PDF file\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Create a PDF reader object\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = []\n",
    "        \n",
    "        # Loop through each page in the PDF\n",
    "        for page in pdf_reader.pages:\n",
    "            # Extract text from each page and append to the list\n",
    "            text.append(page.extract_text())\n",
    "        \n",
    "        # Join all texts into a single string\n",
    "        return '\\n'.join(text)\n",
    "\n",
    "# Example usage: replace 'yourfile.pdf' with your PDF file path\n",
    "pdf_text = read_pdf_as_string('../test_file/qie.pdf')\n",
    "# print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chen', 'O'),\n",
       " ('##yu', 'O'),\n",
       " ('w', 'O'),\n",
       " ('ang', 'O'),\n",
       " ('(', 'O'),\n",
       " ('clair', 'O'),\n",
       " ('e', 'O'),\n",
       " (')', 'O'),\n",
       " ('chen', 'O'),\n",
       " ('##yu', 'O'),\n",
       " ('.', 'O'),\n",
       " ('wang', 'O'),\n",
       " ('##00', 'O'),\n",
       " ('##4', 'O'),\n",
       " ('@', 'O'),\n",
       " ('duke', 'O'),\n",
       " ('.', 'O'),\n",
       " ('e', 'O'),\n",
       " ('du', 'O'),\n",
       " ('|', 'O'),\n",
       " ('(', 'O'),\n",
       " ('91', 'O'),\n",
       " ('##9', 'O'),\n",
       " (')', 'O'),\n",
       " ('64', 'O'),\n",
       " ('##1', 'O'),\n",
       " ('-', 'O'),\n",
       " ('500', 'O'),\n",
       " ('##3', 'O'),\n",
       " ('|', 'O'),\n",
       " ('link', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('din', 'O'),\n",
       " ('|', 'O'),\n",
       " ('gi', 'O'),\n",
       " ('##th', 'O'),\n",
       " ('##hu', 'O'),\n",
       " ('##b', 'O'),\n",
       " ('education', 'O'),\n",
       " ('duke', 'O'),\n",
       " ('un', 'O'),\n",
       " ('##iv', 'O'),\n",
       " ('er', 'O'),\n",
       " ('##sity', 'O'),\n",
       " ('durham', 'O'),\n",
       " (',', 'O'),\n",
       " ('nc', 'O'),\n",
       " (',', 'O'),\n",
       " ('usa', 'O'),\n",
       " ('m', 'O'),\n",
       " ('.', 'O'),\n",
       " ('eng', 'O'),\n",
       " ('.', 'O'),\n",
       " ('in', 'O'),\n",
       " ('el', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('ct', 'O'),\n",
       " ('##rica', 'O'),\n",
       " ('##l', 'O'),\n",
       " ('&', 'O'),\n",
       " ('computer', 'O'),\n",
       " ('engine', 'O'),\n",
       " ('erin', 'O'),\n",
       " ('##g', 'O'),\n",
       " ('[', 'O'),\n",
       " ('ex', 'O'),\n",
       " ('##p', 'O'),\n",
       " ('e', 'O'),\n",
       " ('ct', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('d', 'O'),\n",
       " (']', 'O'),\n",
       " ('202', 'O'),\n",
       " ('##3', 'O'),\n",
       " ('/', 'O'),\n",
       " ('08', 'O'),\n",
       " ('–', 'O'),\n",
       " ('202', 'O'),\n",
       " ('##5', 'O'),\n",
       " ('/', 'O'),\n",
       " ('01', 'O'),\n",
       " ('•', 'O'),\n",
       " ('concentration', 'O'),\n",
       " (':', 'O'),\n",
       " ('data', 'B-Skill'),\n",
       " ('a', 'O'),\n",
       " ('na', 'O'),\n",
       " ('##ly', 'O'),\n",
       " ('##tics', 'O'),\n",
       " ('&', 'O'),\n",
       " ('machine', 'B-Skill'),\n",
       " ('learning', 'O'),\n",
       " ('•', 'O'),\n",
       " ('re', 'O'),\n",
       " ('##le', 'O'),\n",
       " ('van', 'O'),\n",
       " ('##t', 'O'),\n",
       " ('courses', 'O'),\n",
       " (':', 'O'),\n",
       " ('data', 'B-Skill'),\n",
       " ('science', 'O'),\n",
       " (',', 'O'),\n",
       " ('data', 'B-Skill'),\n",
       " ('visual', 'I-Skill'),\n",
       " ('##ization', 'I-Skill'),\n",
       " (',', 'O'),\n",
       " ('machine', 'B-Skill'),\n",
       " ('learning', 'B-Skill'),\n",
       " (',', 'O'),\n",
       " ('de', 'O'),\n",
       " ('ep', 'O'),\n",
       " ('learning', 'O'),\n",
       " (',', 'O'),\n",
       " ('statistical', 'B-Skill'),\n",
       " ('a', 'O'),\n",
       " ('na', 'O'),\n",
       " ('##lysis', 'O'),\n",
       " (',', 'O'),\n",
       " ('a', 'O'),\n",
       " ('/', 'O'),\n",
       " ('b', 'O'),\n",
       " ('t', 'O'),\n",
       " ('est', 'O'),\n",
       " ('##ing', 'O'),\n",
       " ('duke', 'O'),\n",
       " ('kun', 'O'),\n",
       " ('##shan', 'O'),\n",
       " ('un', 'O'),\n",
       " ('##iv', 'O'),\n",
       " ('er', 'O'),\n",
       " ('##sity', 'O'),\n",
       " ('/', 'O'),\n",
       " ('duke', 'O'),\n",
       " ('un', 'O'),\n",
       " ('##iv', 'O'),\n",
       " ('er', 'O'),\n",
       " ('##sity', 'O'),\n",
       " ('kun', 'O'),\n",
       " ('##shan', 'O'),\n",
       " (',', 'O'),\n",
       " ('china', 'O'),\n",
       " ('/', 'O'),\n",
       " ('durham', 'O'),\n",
       " (',', 'O'),\n",
       " ('nc', 'O'),\n",
       " (',', 'O'),\n",
       " ('usa', 'O'),\n",
       " ('b', 'O'),\n",
       " ('.', 'O'),\n",
       " ('s', 'O'),\n",
       " ('.', 'O'),\n",
       " ('in', 'O'),\n",
       " ('a', 'O'),\n",
       " ('pp', 'O'),\n",
       " ('##lie', 'O'),\n",
       " ('d', 'O'),\n",
       " ('math', 'O'),\n",
       " ('&', 'O'),\n",
       " ('computational', 'O'),\n",
       " ('science', 'O'),\n",
       " ('(', 'O'),\n",
       " ('dual', 'O'),\n",
       " ('de', 'O'),\n",
       " ('##gr', 'O'),\n",
       " ('e', 'O'),\n",
       " ('e', 'O'),\n",
       " ('by', 'O'),\n",
       " ('d', 'O'),\n",
       " ('##k', 'O'),\n",
       " ('u', 'O'),\n",
       " ('&', 'O'),\n",
       " ('duke', 'O'),\n",
       " (')', 'O'),\n",
       " ('2019', 'O'),\n",
       " ('/', 'O'),\n",
       " ('08', 'O'),\n",
       " ('–', 'O'),\n",
       " ('202', 'O'),\n",
       " ('##3', 'O'),\n",
       " ('/', 'O'),\n",
       " ('05', 'O'),\n",
       " ('•', 'O'),\n",
       " ('gp', 'O'),\n",
       " ('a', 'O'),\n",
       " (':', 'O'),\n",
       " ('3', 'O'),\n",
       " ('.', 'O'),\n",
       " ('81', 'O'),\n",
       " ('/', 'O'),\n",
       " ('4', 'O'),\n",
       " ('.', 'O'),\n",
       " ('0', 'O'),\n",
       " ('|', 'O'),\n",
       " ('dean', 'O'),\n",
       " ('’', 'O'),\n",
       " ('s', 'O'),\n",
       " ('list', 'O'),\n",
       " (':', 'O'),\n",
       " ('fa', 'O'),\n",
       " ('##l', 'O'),\n",
       " ('l', 'O'),\n",
       " ('2019', 'O'),\n",
       " (',', 'O'),\n",
       " ('spring', 'O'),\n",
       " ('202', 'O'),\n",
       " ('##2', 'O'),\n",
       " ('(', 'O'),\n",
       " ('distinction', 'O'),\n",
       " (')', 'O'),\n",
       " ('w', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##k', 'O'),\n",
       " ('ex', 'O'),\n",
       " ('##p', 'O'),\n",
       " ('erie', 'O'),\n",
       " ('##nce', 'O'),\n",
       " ('xiao', 'O'),\n",
       " ('##hong', 'O'),\n",
       " ('##shu', 'O'),\n",
       " ('(', 'O'),\n",
       " ('china', 'O'),\n",
       " ('’', 'O'),\n",
       " ('s', 'O'),\n",
       " ('ins', 'O'),\n",
       " ('##tagram', 'O'),\n",
       " (',', 'O'),\n",
       " ('china', 'O'),\n",
       " ('’', 'O'),\n",
       " ('s', 'O'),\n",
       " ('most', 'O'),\n",
       " ('p', 'O'),\n",
       " ('op', 'O'),\n",
       " ('##ular', 'O'),\n",
       " ('lifestyle', 'O'),\n",
       " ('-', 'O'),\n",
       " ('sharing', 'O'),\n",
       " ('platform', 'O'),\n",
       " (')', 'O'),\n",
       " ('shanghai', 'O'),\n",
       " (',', 'O'),\n",
       " ('china', 'O'),\n",
       " ('data', 'O'),\n",
       " ('a', 'O'),\n",
       " ('na', 'O'),\n",
       " ('##ly', 'O'),\n",
       " ('##st', 'O'),\n",
       " ('intern', 'O'),\n",
       " ('|', 'O'),\n",
       " ('a', 'O'),\n",
       " ('ds', 'O'),\n",
       " ('t', 'O'),\n",
       " ('ea', 'O'),\n",
       " ('##m', 'O'),\n",
       " ('202', 'O'),\n",
       " ('##3', 'O'),\n",
       " ('/', 'O'),\n",
       " ('05', 'O'),\n",
       " ('–', 'O'),\n",
       " ('202', 'O'),\n",
       " ('##3', 'O'),\n",
       " ('/', 'O'),\n",
       " ('08', 'O'),\n",
       " ('•', 'O'),\n",
       " ('design', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('d', 'O'),\n",
       " ('and', 'O'),\n",
       " ('opt', 'O'),\n",
       " ('##imi', 'O'),\n",
       " ('##ze', 'O'),\n",
       " ('d', 'O'),\n",
       " ('ok', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('metric', 'O'),\n",
       " ('##s', 'O'),\n",
       " ('such', 'O'),\n",
       " ('as', 'O'),\n",
       " ('ct', 'B-Skill'),\n",
       " ('##r', 'B-Skill'),\n",
       " (',', 'O'),\n",
       " ('cpc', 'B-Skill'),\n",
       " (',', 'O'),\n",
       " ('cp', 'O'),\n",
       " ('a', 'O'),\n",
       " ('to', 'O'),\n",
       " ('e', 'O'),\n",
       " ('val', 'O'),\n",
       " ('##uate', 'O'),\n",
       " ('and', 'O'),\n",
       " ('track', 'O'),\n",
       " ('brand', 'O'),\n",
       " ('ad', 'O'),\n",
       " ('##v', 'O'),\n",
       " ('er', 'O'),\n",
       " ('##tis', 'O'),\n",
       " ('##ing', 'O'),\n",
       " ('p', 'O'),\n",
       " ('er', 'O'),\n",
       " ('##form', 'O'),\n",
       " ('##ance', 'O'),\n",
       " ('•', 'O'),\n",
       " ('conduct', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('d', 'O'),\n",
       " ('de', 'O'),\n",
       " ('ep', 'O'),\n",
       " ('di', 'O'),\n",
       " ('##v', 'O'),\n",
       " ('e', 'O'),\n",
       " ('analysis', 'O'),\n",
       " ('base', 'O'),\n",
       " ('d', 'O'),\n",
       " ('on', 'O'),\n",
       " ('consumer', 'O'),\n",
       " ('durable', 'O'),\n",
       " ('##s', 'O'),\n",
       " ('to', 'O'),\n",
       " ('e', 'O'),\n",
       " ('xp', 'O'),\n",
       " ('##lor', 'O'),\n",
       " ('e', 'O'),\n",
       " ('the', 'O'),\n",
       " ('user', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('o', 'O'),\n",
       " ('##ﬁ', 'O'),\n",
       " ('##le', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('e', 'O'),\n",
       " ('##fer', 'O'),\n",
       " ('en', 'O'),\n",
       " ('##ce', 'O'),\n",
       " ('(', 'O'),\n",
       " ('age', 'O'),\n",
       " (',', 'O'),\n",
       " ('gender', 'O'),\n",
       " (',', 'O'),\n",
       " ('top', 'O'),\n",
       " ('engagement', 'O'),\n",
       " ('p', 'O'),\n",
       " ('os', 'O'),\n",
       " ('##ts', 'O'),\n",
       " (')', 'O'),\n",
       " (';', 'O'),\n",
       " ('opt', 'O'),\n",
       " ('##imi', 'O'),\n",
       " ('##ze', 'O'),\n",
       " ('d', 'O'),\n",
       " ('p', 'O'),\n",
       " ('er', 'O'),\n",
       " ('##son', 'O'),\n",
       " ('##ali', 'O'),\n",
       " ('##ze', 'O'),\n",
       " ('d', 'O'),\n",
       " ('ads', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('om', 'O'),\n",
       " ('##ot', 'O'),\n",
       " ('##ion', 'O'),\n",
       " ('strategy', 'O'),\n",
       " ('by', 'O'),\n",
       " ('f', 'O'),\n",
       " ('##o', 'O'),\n",
       " ('cu', 'O'),\n",
       " ('##sing', 'O'),\n",
       " ('those', 'O'),\n",
       " ('high', 'O'),\n",
       " ('engagement', 'O'),\n",
       " ('users', 'O'),\n",
       " ('under', 'O'),\n",
       " ('brand', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('o', 'O'),\n",
       " ('duct', 'O'),\n",
       " ('##s', 'O'),\n",
       " ('•', 'O'),\n",
       " ('perform', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('d', 'O'),\n",
       " ('bi', 'O'),\n",
       " ('mo', 'O'),\n",
       " ('nt', 'O'),\n",
       " ('##hly', 'O'),\n",
       " ('paid', 'O'),\n",
       " ('listing', 'O'),\n",
       " ('ads', 'O'),\n",
       " ('r', 'O'),\n",
       " ('ep', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##t', 'O'),\n",
       " ('analysis', 'O'),\n",
       " ('by', 'O'),\n",
       " ('de', 'O'),\n",
       " ('##ﬁ', 'O'),\n",
       " ('##ning', 'O'),\n",
       " ('analytics', 'O'),\n",
       " ('frame', 'O'),\n",
       " ('w', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##k', 'O'),\n",
       " ('to', 'O'),\n",
       " ('analyze', 'O'),\n",
       " ('cost', 'O'),\n",
       " ('-', 'O'),\n",
       " ('r', 'O'),\n",
       " ('el', 'O'),\n",
       " ('##ate', 'O'),\n",
       " ('d', 'O'),\n",
       " ('indicators', 'O'),\n",
       " ('fr', 'O'),\n",
       " ('om', 'O'),\n",
       " ('various', 'O'),\n",
       " ('categories', 'O'),\n",
       " ('and', 'O'),\n",
       " ('top', 'O'),\n",
       " ('sea', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('ch', 'O'),\n",
       " ('ke', 'O'),\n",
       " ('y', 'O'),\n",
       " ('w', 'O'),\n",
       " ('or', 'O'),\n",
       " ('ds', 'O'),\n",
       " ('to', 'O'),\n",
       " ('capt', 'O'),\n",
       " ('##ur', 'O'),\n",
       " ('e', 'O'),\n",
       " ('p', 'O'),\n",
       " ('op', 'O'),\n",
       " ('##ular', 'O'),\n",
       " ('tr', 'O'),\n",
       " ('ends', 'O'),\n",
       " ('on', 'O'),\n",
       " ('the', 'O'),\n",
       " ('user', 'O'),\n",
       " ('le', 'O'),\n",
       " ('v', 'O'),\n",
       " ('el', 'O'),\n",
       " (';', 'O'),\n",
       " ('sum', 'O'),\n",
       " ('##mar', 'O'),\n",
       " ('##ize', 'O'),\n",
       " ('d', 'O'),\n",
       " ('ke', 'O'),\n",
       " ('y', 'O'),\n",
       " ('insights', 'O'),\n",
       " ('to', 'O'),\n",
       " ('leadership', 'O'),\n",
       " ('•', 'O'),\n",
       " ('le', 'O'),\n",
       " ('v', 'O'),\n",
       " ('era', 'O'),\n",
       " ('##ge', 'O'),\n",
       " ('d', 'O'),\n",
       " ('sql', 'O'),\n",
       " ('to', 'O'),\n",
       " ('p', 'O'),\n",
       " ('er', 'O'),\n",
       " ('##form', 'O'),\n",
       " ('data', 'O'),\n",
       " ('quality', 'O'),\n",
       " ('che', 'O'),\n",
       " ('ck', 'O'),\n",
       " ('and', 'O'),\n",
       " ('validation', 'O'),\n",
       " ('on', 'O'),\n",
       " ('user', 'O'),\n",
       " ('tags', 'O'),\n",
       " (';', 'O'),\n",
       " ('help', 'O'),\n",
       " ('e', 'O'),\n",
       " ('d', 'O'),\n",
       " ('eng', 'O'),\n",
       " ('team', 'O'),\n",
       " ('imp', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('o', 'O'),\n",
       " ('v', 'O'),\n",
       " ('e', 'O'),\n",
       " ('brand', 'O'),\n",
       " ('tag', 'O'),\n",
       " ('accuracy', 'O'),\n",
       " ('po', 'O'),\n",
       " ('##iz', 'O'),\n",
       " ('##on', 'O'),\n",
       " ('(', 'O'),\n",
       " ('china', 'O'),\n",
       " ('’', 'O'),\n",
       " ('s', 'O'),\n",
       " ('largest', 'O'),\n",
       " ('tr', 'O'),\n",
       " ('end', 'O'),\n",
       " ('##y', 'O'),\n",
       " ('brand', 'O'),\n",
       " ('e', 'O'),\n",
       " ('-', 'O'),\n",
       " ('com', 'O'),\n",
       " ('##mer', 'O'),\n",
       " ('ce', 'O'),\n",
       " ('app', 'O'),\n",
       " (')', 'O'),\n",
       " ('shanghai', 'O'),\n",
       " (',', 'O'),\n",
       " ('china', 'O'),\n",
       " ('data', 'O'),\n",
       " ('a', 'O'),\n",
       " ('na', 'O'),\n",
       " ('##ly', 'O'),\n",
       " ('##st', 'O'),\n",
       " ('intern', 'O'),\n",
       " ('|', 'O'),\n",
       " ('business', 'O'),\n",
       " ('a', 'O'),\n",
       " ('na', 'O'),\n",
       " ('##lysis', 'O'),\n",
       " ('department', 'O'),\n",
       " ('202', 'O'),\n",
       " ('##2', 'O'),\n",
       " ('/', 'O'),\n",
       " ('06', 'O'),\n",
       " ('–', 'O'),\n",
       " ('202', 'O'),\n",
       " ('##2', 'O'),\n",
       " ('/', 'O'),\n",
       " ('11', 'O'),\n",
       " ('•', 'O'),\n",
       " ('built', 'O'),\n",
       " ('3', 'O'),\n",
       " ('master', 'O'),\n",
       " ('tables', 'O'),\n",
       " ('fr', 'O'),\n",
       " ('om', 'O'),\n",
       " ('ups', 'O'),\n",
       " ('##tr', 'O'),\n",
       " ('ea', 'O'),\n",
       " ('##m', 'O'),\n",
       " ('raw', 'O'),\n",
       " ('data', 'O'),\n",
       " ('sour', 'O'),\n",
       " ('ce', 'O'),\n",
       " ('##s', 'O'),\n",
       " ('by', 'O'),\n",
       " ('conducting', 'O'),\n",
       " ('data', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('e', 'O'),\n",
       " ('-', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('o', 'O'),\n",
       " ('ce', 'O'),\n",
       " ('##ssing', 'O'),\n",
       " ('and', 'O'),\n",
       " ('integrate', 'O'),\n",
       " ('d', 'O'),\n",
       " ('sales', 'O'),\n",
       " ('data', 'O'),\n",
       " ('ac', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('os', 'O'),\n",
       " ('##s', 'O'),\n",
       " ('40', 'O'),\n",
       " ('dimensions', 'O'),\n",
       " ('(', 'O'),\n",
       " ('cost', 'O'),\n",
       " (',', 'O'),\n",
       " ('r', 'O'),\n",
       " ('e', 'O'),\n",
       " ('v', 'O'),\n",
       " ('en', 'O'),\n",
       " ('##ue', 'O'),\n",
       " (',', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('om', 'O'),\n",
       " ('##ot', 'O'),\n",
       " ('##ion', 'O'),\n",
       " (')', 'O'),\n",
       " (';', 'O'),\n",
       " ('st', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('ea', 'O'),\n",
       " ('##ml', 'O'),\n",
       " ('##ine', 'O'),\n",
       " ('d', 'O'),\n",
       " ('the', 'O'),\n",
       " ('generation', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('o', 'O'),\n",
       " ('ce', 'O'),\n",
       " ('##ss', 'O'),\n",
       " ('of', 'O'),\n",
       " ('daily', 'O'),\n",
       " ('and', 'O'),\n",
       " ('monthly', 'O'),\n",
       " ('data', 'O'),\n",
       " ('r', 'O'),\n",
       " ('ep', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##ts', 'O'),\n",
       " ('by', 'O'),\n",
       " ('30', 'O'),\n",
       " ('%', 'O'),\n",
       " ('•', 'O'),\n",
       " ('imp', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('o', 'O'),\n",
       " ('v', 'O'),\n",
       " ('e', 'O'),\n",
       " ('d', 'O'),\n",
       " ('cu', 'O'),\n",
       " ('##rr', 'O'),\n",
       " ('en', 'O'),\n",
       " ('##t', 'O'),\n",
       " ('data', 'O'),\n",
       " ('r', 'O'),\n",
       " ('ep', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##ting', 'O'),\n",
       " ('pip', 'O'),\n",
       " ('eli', 'O'),\n",
       " ('##ne', 'O'),\n",
       " ('[UNK]', 'O'),\n",
       " ('by', 'O'),\n",
       " ('20', 'O'),\n",
       " ('%', 'O'),\n",
       " ('th', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('ou', 'O'),\n",
       " ('##gh', 'O'),\n",
       " ('opt', 'O'),\n",
       " ('##imi', 'O'),\n",
       " ('##zing', 'O'),\n",
       " ('sql', 'O'),\n",
       " ('functions', 'O'),\n",
       " ('and', 'O'),\n",
       " ('cr', 'O'),\n",
       " ('eat', 'O'),\n",
       " ('ing', 'O'),\n",
       " ('inter', 'O'),\n",
       " ('##me', 'O'),\n",
       " ('dia', 'O'),\n",
       " ('##te', 'O'),\n",
       " ('tables', 'O'),\n",
       " ('•', 'O'),\n",
       " ('built', 'O'),\n",
       " ('data', 'O'),\n",
       " ('visual', 'O'),\n",
       " ('##ization', 'O'),\n",
       " ('dash', 'O'),\n",
       " ('##b', 'O'),\n",
       " ('o', 'O'),\n",
       " ('##ar', 'O'),\n",
       " ('ds', 'O'),\n",
       " ('th', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('ou', 'O'),\n",
       " ('##gh', 'O'),\n",
       " ('po', 'O'),\n",
       " ('w', 'O'),\n",
       " ('er', 'O'),\n",
       " ('bi', 'O'),\n",
       " ('to', 'O'),\n",
       " ('help', 'O'),\n",
       " ('monitor', 'O'),\n",
       " ('and', 'O'),\n",
       " ('analyze', 'O'),\n",
       " ('monthly', 'O'),\n",
       " ('/', 'O'),\n",
       " ('quarterly', 'O'),\n",
       " ('sales', 'O'),\n",
       " ('data', 'O'),\n",
       " ('of', 'O'),\n",
       " ('sp', 'O'),\n",
       " ('e', 'O'),\n",
       " ('ci', 'O'),\n",
       " ('##ﬁ', 'O'),\n",
       " ('##c', 'O'),\n",
       " ('categories', 'O'),\n",
       " ('and', 'O'),\n",
       " ('com', 'O'),\n",
       " ('##par', 'O'),\n",
       " ('e', 'O'),\n",
       " ('sales', 'O'),\n",
       " ('data', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('same', 'O'),\n",
       " ('cat', 'O'),\n",
       " ('##ego', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('y', 'O'),\n",
       " ('b', 'O'),\n",
       " ('et', 'O'),\n",
       " ('##w', 'O'),\n",
       " ('e', 'O'),\n",
       " ('en', 'O'),\n",
       " ('po', 'O'),\n",
       " ('##iz', 'O'),\n",
       " ('##on', 'O'),\n",
       " ('and', 'O'),\n",
       " ('com', 'O'),\n",
       " ('##p', 'O'),\n",
       " ('et', 'O'),\n",
       " ('##ing', 'O'),\n",
       " ('companies', 'O'),\n",
       " ('•', 'O'),\n",
       " ('det', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('ct', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('d', 'O'),\n",
       " ('and', 'O'),\n",
       " ('class', 'O'),\n",
       " ('##i', 'O'),\n",
       " ('##ﬁ', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('d', 'O'),\n",
       " ('the', 'O'),\n",
       " ('impact', 'O'),\n",
       " ('of', 'O'),\n",
       " ('th', 'O'),\n",
       " ('e', 'O'),\n",
       " ('subsidy', 'O'),\n",
       " ('campaign', 'O'),\n",
       " ('using', 'O'),\n",
       " ('t', 'O'),\n",
       " ('e', 'O'),\n",
       " ('x', 'O'),\n",
       " ('##t', 'O'),\n",
       " ('analysis', 'O'),\n",
       " ('to', 'O'),\n",
       " ('imp', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('o', 'O'),\n",
       " ('v', 'O'),\n",
       " ('e', 'O'),\n",
       " ('strategies', 'O'),\n",
       " ('for', 'O'),\n",
       " ('b', 'O'),\n",
       " ('et', 'O'),\n",
       " ('##ter', 'O'),\n",
       " ('[UNK]', 'O'),\n",
       " ('ct', 'O'),\n",
       " ('##iv', 'O'),\n",
       " ('en', 'O'),\n",
       " ('##ess', 'O'),\n",
       " ('china', 'O'),\n",
       " ('construction', 'O'),\n",
       " ('bank', 'O'),\n",
       " ('(', 'O'),\n",
       " ('kun', 'O'),\n",
       " ('##shan', 'O'),\n",
       " ('branch', 'O'),\n",
       " (')', 'O'),\n",
       " ('kun', 'O'),\n",
       " ('##shan', 'O'),\n",
       " (',', 'O'),\n",
       " ('china', 'O'),\n",
       " ('data', 'O'),\n",
       " ('engine', 'O'),\n",
       " ('erin', 'O'),\n",
       " ('##g', 'O'),\n",
       " ('intern', 'O'),\n",
       " ('|', 'O'),\n",
       " ('fin', 'O'),\n",
       " ('##te', 'O'),\n",
       " ('ch', 'O'),\n",
       " ('department', 'O'),\n",
       " ('2021', 'O'),\n",
       " ('/', 'O'),\n",
       " ('03', 'O'),\n",
       " ('–', 'O'),\n",
       " ('2021', 'O'),\n",
       " ('/', 'O'),\n",
       " ('05', 'O'),\n",
       " ('•', 'O'),\n",
       " ('su', 'O'),\n",
       " ('##pp', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##te', 'O'),\n",
       " ('d', 'O'),\n",
       " ('the', 'O'),\n",
       " ('daily', 'O'),\n",
       " ('data', 'O'),\n",
       " ('op', 'O'),\n",
       " ('era', 'O'),\n",
       " ('##tions', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('inc', 'O'),\n",
       " ('##lus', 'O'),\n",
       " ('##iv', 'O'),\n",
       " ('e', 'O'),\n",
       " ('business', 'O'),\n",
       " ('departments', 'O'),\n",
       " (',', 'O'),\n",
       " ('such', 'O'),\n",
       " ('as', 'O'),\n",
       " ('data', 'O'),\n",
       " ('e', 'O'),\n",
       " ('x', 'O'),\n",
       " ('##tra', 'O'),\n",
       " ('##ction', 'O'),\n",
       " ('of', 'O'),\n",
       " ('loan', 'O'),\n",
       " ('di', 'O'),\n",
       " ('##sb', 'O'),\n",
       " ('##urse', 'O'),\n",
       " ('##ment', 'O'),\n",
       " ('•', 'O'),\n",
       " ('sum', 'O'),\n",
       " ('##mar', 'O'),\n",
       " ('##ize', 'O'),\n",
       " ('d', 'O'),\n",
       " ('the', 'O'),\n",
       " ('bank', 'O'),\n",
       " ('car', 'O'),\n",
       " ('d', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('o', 'O'),\n",
       " ('ce', 'O'),\n",
       " ('##ssing', 'O'),\n",
       " ('data', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('personal', 'O'),\n",
       " ('finance', 'O'),\n",
       " ('department', 'O'),\n",
       " (';', 'O'),\n",
       " ('built', 'O'),\n",
       " ('auto', 'O'),\n",
       " ('##mate', 'O'),\n",
       " ('d', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('o', 'O'),\n",
       " ('ce', 'O'),\n",
       " ('##ssing', 'O'),\n",
       " ('scripts', 'O'),\n",
       " ('th', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('ou', 'O'),\n",
       " ('##gh', 'O'),\n",
       " ('python', 'O'),\n",
       " ('to', 'O'),\n",
       " ('generate', 'O'),\n",
       " ('daily', 'O'),\n",
       " ('r', 'O'),\n",
       " ('ep', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##ts', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('ag', 'O'),\n",
       " ('##gr', 'O'),\n",
       " ('e', 'O'),\n",
       " ('##gate', 'O'),\n",
       " ('d', 'O'),\n",
       " ('them', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('master', 'O'),\n",
       " ('table', 'O'),\n",
       " ('of', 'O'),\n",
       " ('pe', 'O'),\n",
       " ('op', 'O'),\n",
       " ('##le', 'O'),\n",
       " ('’', 'O'),\n",
       " ('s', 'O'),\n",
       " ('bank', 'O'),\n",
       " ('of', 'O'),\n",
       " ('china', 'O'),\n",
       " ('•', 'O'),\n",
       " ('sum', 'O'),\n",
       " ('##mar', 'O'),\n",
       " ('##ize', 'O'),\n",
       " ('d', 'O'),\n",
       " ('the', 'O'),\n",
       " ('cr', 'O'),\n",
       " ('e', 'O'),\n",
       " ('di', 'O'),\n",
       " ('##t', 'O'),\n",
       " ('r', 'O'),\n",
       " ('ep', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##ts', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('business', 'O'),\n",
       " ('department', 'O'),\n",
       " (',', 'O'),\n",
       " ('wr', 'O'),\n",
       " ('ot', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('auto', 'O'),\n",
       " ('##mate', 'O'),\n",
       " ('d', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('o', 'O'),\n",
       " ('ce', 'O'),\n",
       " ('##ssing', 'O'),\n",
       " ('scripts', 'O'),\n",
       " ('th', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('ou', 'O'),\n",
       " ('##gh', 'O'),\n",
       " ('python', 'O'),\n",
       " ('to', 'O'),\n",
       " ('col', 'O'),\n",
       " ('##le', 'O'),\n",
       " ('ct', 'O'),\n",
       " ('ke', 'O'),\n",
       " ('y', 'O'),\n",
       " ('information', 'O'),\n",
       " ('sc', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('e', 'O'),\n",
       " ('en', 'O'),\n",
       " ('##shot', 'O'),\n",
       " ('##s', 'O'),\n",
       " (',', 'O'),\n",
       " ('helping', 'O'),\n",
       " ('to', 'O'),\n",
       " ('inc', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('ease', 'O'),\n",
       " ('the', 'O'),\n",
       " ('w', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##k', 'O'),\n",
       " ('[UNK]', 'O'),\n",
       " ('th', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('e', 'O'),\n",
       " ('e', 'O'),\n",
       " ('times', 'O'),\n",
       " ('as', 'O'),\n",
       " ('b', 'O'),\n",
       " ('e', 'O'),\n",
       " ('##for', 'O'),\n",
       " ('e', 'O'),\n",
       " ('•', 'O'),\n",
       " ('opt', 'O'),\n",
       " ('##imi', 'O'),\n",
       " ('##ze', 'O'),\n",
       " ('d', 'O'),\n",
       " ('all', 'O'),\n",
       " ('scripts', 'O'),\n",
       " ('base', 'O'),\n",
       " ('d', 'O'),\n",
       " ('on', 'O'),\n",
       " ('users', 'O'),\n",
       " ('’', 'O'),\n",
       " ('fe', 'O'),\n",
       " ('e', 'O'),\n",
       " ('db', 'O'),\n",
       " ('##ack', 'O'),\n",
       " ('and', 'O'),\n",
       " ('e', 'O'),\n",
       " ('v', 'O'),\n",
       " ('en', 'O'),\n",
       " ('##tua', 'O'),\n",
       " ('##lly', 'O'),\n",
       " ('integrate', 'O'),\n",
       " ('d', 'O'),\n",
       " ('it', 'O'),\n",
       " ('into', 'O'),\n",
       " ('the', 'O'),\n",
       " ('[UNK]', 'O'),\n",
       " ('w', 'O'),\n",
       " ('or', 'O'),\n",
       " ('##k', 'O'),\n",
       " ('##ﬂ', 'O'),\n",
       " ('##o', 'O'),\n",
       " ('w', 'O'),\n",
       " ('pr', 'O'),\n",
       " ('o', 'O'),\n",
       " ('##je', 'O'),\n",
       " ('ct', 'O'),\n",
       " ('##s', 'O'),\n",
       " ('2021', 'O'),\n",
       " ('inter', 'O'),\n",
       " ('disc', 'O'),\n",
       " ('##ip', 'O'),\n",
       " ('##lina', 'O'),\n",
       " ('##r', 'O'),\n",
       " ('y', 'O'),\n",
       " ('contest', 'O'),\n",
       " ('in', 'O'),\n",
       " ('mo', 'O'),\n",
       " ('del', 'O'),\n",
       " ('##ing', 'O'),\n",
       " ('|', 'O'),\n",
       " ('python', 'O'),\n",
       " ('kun', 'O'),\n",
       " ('##shan', 'O'),\n",
       " (',', 'O'),\n",
       " ('china', 'O'),\n",
       " ('t', 'O'),\n",
       " ('ea', 'O'),\n",
       " ('##m', 'O'),\n",
       " ('leader', 'O'),\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence = \"Jingwei Li William is a first-year student at Duke University pursuing a Master’s in Artificial Intelligence. He has rich experience utilizing Python, SQL, and data visualization tools to derive insights. He has solid data science skills including Python, R as well as mastery of data science tools such as numpy, pandas, and scikit-learn. He has provided digital solutions to different real business problems through his internship in various industries. He is currently working with Cadence Cash, using machine-learning skills to provide unbiased and fair loaning decisions for small businesses. he is also good at machine learning\"\n",
    "# divide pdf_text into sub sentences, length = 80\n",
    "sentence = pdf_text\n",
    "sub_sentences = [sentence[i:i+300] for i in range(0, len(sentence), 300)]\n",
    "\n",
    "skills = []; meta_wp_preds = []\n",
    "\n",
    "for sub_sentence in sub_sentences:\n",
    "    inputs = tokenizer(sub_sentence, return_tensors=\"pt\", max_length=MAX_LEN, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    \n",
    "    ids = inputs['input_ids'].to(device, dtype = torch.long)\n",
    "    mask = inputs['attention_mask'].to(device, dtype = torch.long)\n",
    "    \n",
    "    outputs = model(ids, mask)\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "    flattened_predictions = torch.argmax(active_logits, axis=1) \n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "    \n",
    "    token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "    \n",
    "    meta_wp_preds.extend(wp_preds)\n",
    "\n",
    "    for item in wp_preds:\n",
    "        if item[1] in ['B-Skill', 'I-Skill'] and item[0] not in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "            skills.append(item[0])\n",
    "\n",
    "cleaned_preds = [t for t in meta_wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]\n",
    "cleaned_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write cleaned preds to txt\n",
    "with open('../test_file/skills.txt', 'w') as f:\n",
    "    for item in cleaned_preds:\n",
    "        f.write(item[0] + ' ' + item[1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 'B-Skill'),\n",
       " ('machine', 'B-Skill'),\n",
       " ('data', 'B-Skill'),\n",
       " ('data', 'B-Skill'),\n",
       " ('visual', 'I-Skill'),\n",
       " ('##ization', 'I-Skill'),\n",
       " ('machine', 'B-Skill'),\n",
       " ('learning', 'B-Skill'),\n",
       " ('statistical', 'B-Skill'),\n",
       " ('ct', 'B-Skill'),\n",
       " ('##r', 'B-Skill'),\n",
       " ('cpc', 'B-Skill'),\n",
       " ('og', 'B-Skill'),\n",
       " ('##ram', 'B-Skill'),\n",
       " ('##ming', 'B-Skill'),\n",
       " ('python', 'B-Skill'),\n",
       " ('sql', 'B-Skill'),\n",
       " ('my', 'B-Skill'),\n",
       " ('##s', 'B-Skill'),\n",
       " ('##q', 'B-Skill'),\n",
       " ('##l', 'B-Skill'),\n",
       " ('java', 'B-Skill'),\n",
       " ('r', 'B-Skill'),\n",
       " ('julia', 'B-Skill'),\n",
       " ('panda', 'B-Skill'),\n",
       " ('##s', 'B-Skill'),\n",
       " ('nu', 'B-Skill'),\n",
       " ('##mp', 'B-Skill'),\n",
       " ('##y', 'B-Skill'),\n",
       " ('sci', 'B-Skill'),\n",
       " ('##kit', 'B-Skill'),\n",
       " ('excel', 'B-Skill'),\n",
       " ('sum', 'B-Skill'),\n",
       " ('##if', 'B-Skill'),\n",
       " ('##s', 'B-Skill'),\n",
       " ('v', 'B-Skill'),\n",
       " ('##lo', 'B-Skill'),\n",
       " ('##ok', 'B-Skill'),\n",
       " ('up', 'I-Skill'),\n",
       " ('pi', 'B-Skill'),\n",
       " ('##v', 'B-Skill'),\n",
       " ('table', 'I-Skill'),\n",
       " ('data', 'B-Skill'),\n",
       " ('visual', 'I-Skill'),\n",
       " ('##ization', 'I-Skill'),\n",
       " ('machine', 'B-Skill'),\n",
       " ('learning', 'B-Skill'),\n",
       " ('est', 'I-Skill'),\n",
       " ('##ing', 'I-Skill'),\n",
       " ('ex', 'B-Skill'),\n",
       " ('##pl', 'B-Skill'),\n",
       " ('##ora', 'B-Skill'),\n",
       " ('##tor', 'B-Skill'),\n",
       " ('data', 'B-Skill'),\n",
       " ('analysis', 'I-Skill'),\n",
       " ('cluster', 'B-Skill'),\n",
       " ('##ing', 'B-Skill'),\n",
       " ('language', 'B-Skill')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_contained = [t for t in cleaned_preds if t[1] in ['B-Skill', 'I-Skill']]\n",
    "skill_contained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'machine', 'data', 'data visualization', 'machine learning', 'statistical', 'ctr', 'cpc', 'ogramming', 'python', 'sql', 'mysql', 'java', 'r', 'julia', 'pandas', 'numpy', 'scikit', 'excel', 'sumifs', 'vlook up', 'piv', 'table', 'data visualization', 'machine learning', 'esting', 'explorator', 'data analysis', 'clustering', 'language']\n"
     ]
    }
   ],
   "source": [
    "data = cleaned_preds\n",
    "\n",
    "skills = []\n",
    "current_skill = \"\"\n",
    "for token, tag in data:\n",
    "    if 'Skill' in tag:\n",
    "        # If the token starts with '##', remove '##' and append the rest to the current skill\n",
    "        if token.startswith('##'):\n",
    "            current_skill += token[2:]\n",
    "        # Otherwise, add a space before appending the token to the current skill\n",
    "        else:\n",
    "            current_skill += ' ' + token\n",
    "    elif current_skill:\n",
    "        # If the current skill is not empty and the current tag is not a skill, append the current skill to the skills list and reset the current skill\n",
    "        skills.append(current_skill.strip())\n",
    "        current_skill = \"\"\n",
    "\n",
    "# If the last token was a part of a skill, append the current skill to the skills list\n",
    "if current_skill:\n",
    "    skills.append(current_skill.strip())\n",
    "\n",
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jing', 'O'),\n",
       " ('##wei', 'O'),\n",
       " ('li', 'O'),\n",
       " ('william', 'O'),\n",
       " ('is', 'O'),\n",
       " ('a', 'O'),\n",
       " ('first', 'O'),\n",
       " ('-', 'O'),\n",
       " ('year', 'O'),\n",
       " ('student', 'O'),\n",
       " ('at', 'O'),\n",
       " ('duke', 'O'),\n",
       " ('university', 'O'),\n",
       " ('pursuing', 'O'),\n",
       " ('a', 'O'),\n",
       " ('master', 'O'),\n",
       " ('’', 'O'),\n",
       " ('s', 'O'),\n",
       " ('in', 'O'),\n",
       " ('artificial', 'O'),\n",
       " ('intelligence', 'O'),\n",
       " ('.', 'O'),\n",
       " ('he', 'O'),\n",
       " ('has', 'O'),\n",
       " ('rich', 'O'),\n",
       " ('experience', 'O'),\n",
       " ('utilizing', 'O'),\n",
       " ('python', 'B-Skill'),\n",
       " (',', 'O'),\n",
       " ('sql', 'B-Skill'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('data', 'B-Skill'),\n",
       " ('visual', 'I-Skill'),\n",
       " ('##ization', 'I-Skill'),\n",
       " ('tools', 'O'),\n",
       " ('to', 'O'),\n",
       " ('derive', 'O'),\n",
       " ('insights', 'O'),\n",
       " ('.', 'O'),\n",
       " ('he', 'O'),\n",
       " ('has', 'O'),\n",
       " ('solid', 'O'),\n",
       " ('data', 'B-Skill'),\n",
       " ('science', 'O'),\n",
       " ('skills', 'O'),\n",
       " ('including', 'O'),\n",
       " ('python', 'B-Skill'),\n",
       " (',', 'O'),\n",
       " ('r', 'B-Skill'),\n",
       " ('as', 'O'),\n",
       " ('well', 'O'),\n",
       " ('as', 'O'),\n",
       " ('mastery', 'O'),\n",
       " ('of', 'O'),\n",
       " ('data', 'B-Skill'),\n",
       " ('science', 'I-Skill'),\n",
       " ('tools', 'O'),\n",
       " ('s', 'O'),\n",
       " ('uc', 'O'),\n",
       " ('##h', 'O'),\n",
       " ('as', 'O'),\n",
       " ('nu', 'O'),\n",
       " ('##mp', 'O'),\n",
       " ('##y', 'O'),\n",
       " (',', 'O'),\n",
       " ('panda', 'O'),\n",
       " ('##s', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('sci', 'O'),\n",
       " ('##kit', 'O'),\n",
       " ('-', 'O'),\n",
       " ('learn', 'O'),\n",
       " ('.', 'O'),\n",
       " ('he', 'O'),\n",
       " ('has', 'O'),\n",
       " ('provided', 'O'),\n",
       " ('digital', 'O'),\n",
       " ('solutions', 'O'),\n",
       " ('to', 'O'),\n",
       " ('different', 'O'),\n",
       " ('real', 'O'),\n",
       " ('business', 'O'),\n",
       " ('problems', 'O'),\n",
       " ('through', 'O'),\n",
       " ('his', 'O'),\n",
       " ('internship', 'O'),\n",
       " ('in', 'O'),\n",
       " ('various', 'O'),\n",
       " ('industries', 'O'),\n",
       " ('.', 'O'),\n",
       " ('he', 'O'),\n",
       " ('is', 'O'),\n",
       " ('currently', 'O'),\n",
       " ('working', 'O'),\n",
       " ('with', 'O'),\n",
       " ('cadence', 'O'),\n",
       " ('cash', 'O'),\n",
       " (',', 'O'),\n",
       " ('using', 'O'),\n",
       " ('machine', 'O'),\n",
       " ('-', 'O'),\n",
       " ('learning', 'O'),\n",
       " ('skills', 'O'),\n",
       " ('to', 'O'),\n",
       " ('provide', 'O'),\n",
       " ('un', 'O'),\n",
       " ('##bia', 'O'),\n",
       " ('##sed', 'O'),\n",
       " ('and', 'O'),\n",
       " ('fair', 'O'),\n",
       " ('loan', 'O'),\n",
       " ('##ing', 'O'),\n",
       " ('decisions', 'O'),\n",
       " ('for', 'O'),\n",
       " ('small', 'O'),\n",
       " ('businesses', 'O'),\n",
       " ('.', 'O'),\n",
       " ('he', 'O'),\n",
       " ('is', 'O'),\n",
       " ('also', 'O'),\n",
       " ('good', 'O'),\n",
       " ('at', 'O'),\n",
       " ('machine', 'B-Skill'),\n",
       " ('learning', 'O')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zhihan xu knows java , sql , and c + + . he is also a big fan of python and machine learning .\n",
      "['O', 'O', 'O', 'O', 'O', 'B-Skill', 'O', 'B-Skill', 'O', 'O', 'B-Skill', 'B-Skill', 'B-Skill', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Skill', 'O', 'B-Skill', 'B-Skill', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Zhihan Xu knows Java, Sql, and C++. He is also a big fan of Python and machine learning.\"\n",
    "# sentence = pdf_text\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "ids = inputs['input_ids'].to(device, dtype = torch.long)\n",
    "mask = inputs['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "outputs = model(input_ids=ids, attention_mask=mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) \n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 'O'),\n",
       " ('z', 'O'),\n",
       " ('##hi', 'O'),\n",
       " ('##han', 'O'),\n",
       " ('xu', 'O'),\n",
       " ('knows', 'O'),\n",
       " ('java', 'B-Skill'),\n",
       " (',', 'O'),\n",
       " ('sql', 'B-Skill'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('c', 'B-Skill'),\n",
       " ('+', 'B-Skill'),\n",
       " ('+', 'B-Skill'),\n",
       " ('.', 'O'),\n",
       " ('he', 'O'),\n",
       " ('is', 'O'),\n",
       " ('also', 'O'),\n",
       " ('a', 'O'),\n",
       " ('big', 'O'),\n",
       " ('fan', 'O'),\n",
       " ('of', 'O'),\n",
       " ('python', 'B-Skill'),\n",
       " ('and', 'O'),\n",
       " ('machine', 'B-Skill'),\n",
       " ('learning', 'B-Skill'),\n",
       " ('.', 'O'),\n",
       " ('[SEP]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'B-Skill'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'B-Skill'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O'),\n",
       " ('[PAD]', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wp_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
