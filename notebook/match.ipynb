{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "list_j = ['data', 'ai', 'data', 'data science', 'data scraping', 'data', 'database', 'data scraping', 'software', 'data analytics', 'python', 'database querying', 'mysql']\n",
    "list_r = ['python', 'sql', 'data visualization', 'data', 'python', 'r', 'data science', 'machine']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embeddings(client, chunks):\n",
    "    '''\n",
    "    This function creates embeddings for the chunks of text using the OpenAI API.\n",
    "    '''\n",
    "    \n",
    "    def _make_embedding(client, chunk, model=\"text-embedding-3-small\"):\n",
    "        chunk = chunk.replace(\"\\n\", \" \")\n",
    "        return client.embeddings.create(input = [chunk], model=model).data[0].embedding\n",
    "    \n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        embedding = _make_embedding(client, chunk)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "def make_meta_embedding(embeddings, skills):\n",
    "    meta_embedding = {}\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        meta_embedding[skills[i]] = embedding\n",
    "    return meta_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "    \n",
    "openai_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_embedding_j = make_meta_embedding(make_embeddings(client, list_j), list_j)\n",
    "meta_embedding_r = make_meta_embedding(make_embeddings(client, list_r), list_r)\n",
    "\n",
    "meta_embedding_j_copy = meta_embedding_j.copy()\n",
    "# Compute the cosine similarity between the meta embeddings of the two lists\n",
    "# missing_skills = []\n",
    "\n",
    "\n",
    "# Assuming meta_embedding_j and meta_embedding_r are dictionaries with skills as keys and embeddings as values\n",
    "# similarities = {}\n",
    "\n",
    "for skill_j, embedding_j in meta_embedding_j.items():\n",
    "    for skill_r, embedding_r in meta_embedding_r.items():\n",
    "        # Compute the cosine similarity between the two embeddings\n",
    "        similarity = cosine_similarity([embedding_j], [embedding_r])[0][0]\n",
    "        # print(f\"Similarity between {skill_j} and {skill_r}: {similarity}\")\n",
    "        # if the similarity score is above 0.7, remove skills in the dictionary mata_embedding_j\n",
    "        if similarity > 0.7 and skill_j in meta_embedding_j_copy.keys():\n",
    "            # print(f\"Similarity between {skill_j} and {skill_r}: {similarity}\")\n",
    "            # missing_skills.append(skill_j)\n",
    "            del meta_embedding_j_copy[skill_j]\n",
    "\n",
    "# Now similarities is a dictionary with skill pairs as keys and their cosine similarity as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai', 'data scraping', 'software', 'database querying']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(meta_embedding_j_copy.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
